# -*- coding: utf-8 -*-
"""Untitled59.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1odvpx9NOZCwleT6GAl4ltAJVPoWvs2s-
"""

import pandas as pd

# Load the dataset
file_path = "Refined_Merged_Global_Indicators_Cleaned.csv"
df = pd.read_csv(file_path)

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Save the cleaned dataset
cleaned_file_path = "Cleaned_Global_Indicators_No_Duplicates.csv"
df_cleaned.to_csv(cleaned_file_path, index=False)

print(f"Cleaned dataset saved as {cleaned_file_path}")

import pandas as pd

# Load the dataset
file_path = "Refined_Merged_Global_Indicators_Cleaned.csv"
df = pd.read_csv(file_path)

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Save the cleaned dataset
cleaned_file_path = "Cleaned_Global_Indicators_No_Duplicates.csv"
df_cleaned.to_csv(cleaned_file_path, index=False)

# Provide the download link
print(f"Download the cleaned file: [Download Here](sandbox:/{cleaned_file_path})")

import pandas as pd
from google.colab import files

# Load the dataset (Make sure you have uploaded it in Colab)
file_path = "Refined_Merged_Global_Indicators_Cleaned.csv"  # Update with your actual file name
df = pd.read_csv(file_path)

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Save the cleaned dataset
cleaned_file_path = "Cleaned_Global_Indicators_No_Duplicates.csv"
df_cleaned.to_csv(cleaned_file_path, index=False)

# Download the file
files.download(cleaned_file_path)

import pandas as pd
from sklearn.preprocessing import StandardScaler

# Load the dataset
file_path = "Refined_Merged_Global_Indicators_Cleaned.csv"  # Update with your actual file name
df = pd.read_csv(file_path)

# Replace ".." with NaN to clean missing values
df.replace("..", pd.NA, inplace=True)

# Identify year-related numerical columns (those with years in their names)
year_columns = [col for col in df.columns if '[YR' in col]

# Convert all year columns to float (handling scientific notation)
df[year_columns] = df[year_columns].apply(pd.to_numeric, errors='coerce')

# Drop columns that contain only NaN values
df_cleaned = df.dropna(axis=1, how='all')

# Recalculate available year-related numerical columns
existing_year_columns = [col for col in year_columns if col in df_cleaned.columns]

# Identify valid numerical columns (excluding constant columns)
valid_numerical_columns = [col for col in existing_year_columns if df_cleaned[col].nunique() > 1]

# Apply Standardization (Z-score normalization) only on valid numerical columns
scaler = StandardScaler()
df_cleaned[valid_numerical_columns] = scaler.fit_transform(df_cleaned[valid_numerical_columns])

# Save the fixed standardized dataset
standardized_file_path = "Fixed_Standardized_Global_Indicators.csv"
df_cleaned.to_csv(standardized_file_path, index=False)

print(f"✅ Standardized dataset saved as {standardized_file_path}")

df_cleaned.loc[:, valid_numerical_columns] = scaler.fit_transform(df_cleaned[valid_numerical_columns])

import pandas as pd
from sklearn.preprocessing import StandardScaler

# Load the dataset
file_path = "Refined_Merged_Global_Indicators_Cleaned.csv"  # Update with your actual file name
df = pd.read_csv(file_path)

# Replace ".." with NaN to clean missing values
df.replace("..", pd.NA, inplace=True)

# Identify year-related numerical columns (those with years in their names)
year_columns = [col for col in df.columns if '[YR' in col]

# Convert all year columns to float (handling scientific notation)
df[year_columns] = df[year_columns].apply(pd.to_numeric, errors='coerce')

# Drop columns that contain only NaN values
df_cleaned = df.dropna(axis=1, how='all').copy()  # Use .copy() to avoid chained assignment warning

# Recalculate available year-related numerical columns
existing_year_columns = [col for col in year_columns if col in df_cleaned.columns]

# Identify valid numerical columns (excluding constant columns)
valid_numerical_columns = [col for col in existing_year_columns if df_cleaned[col].nunique() > 1]

# Apply Standardization (Z-score normalization) only on valid numerical columns
scaler = StandardScaler()
df_cleaned.loc[:, valid_numerical_columns] = scaler.fit_transform(df_cleaned[valid_numerical_columns])

# Save the fixed standardized dataset
standardized_file_path = "Fixed_Standardized_Global_Indicators.csv"
df_cleaned.to_csv(standardized_file_path, index=False)

print(f"✅ Standardized dataset saved as {standardized_file_path}")

from google.colab import files

# Download the standardized dataset
files.download("Fixed_Standardized_Global_Indicators.csv")